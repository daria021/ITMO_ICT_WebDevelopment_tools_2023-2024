# üåê **api\_service** ‚Äì –æ—Å–Ω–æ–≤–Ω–æ–π API‚Äë—à–ª—é–∑

> –ü–µ—Ä–µ–ø–∏—Å–∞–Ω–æ: –æ–¥–∏–Ω Celery‚Äë–≤–æ—Ä–∫–µ—Ä, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–∞—Ä—Å–µ—Ä–æ–º **—Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ Redis**.
> –ö–∞—Ç–∞–ª–æ–≥ –±–µ–∑ –ø–æ–¥–ø–∞–ø–æ–∫ ‚Äì —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ: `main.py`, `routes.py`, `requests.py`, `responses.py`, `tasks.py`, `models.py`, `database.py`, `celery_app.py`.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
api_service/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ routes.py
‚îú‚îÄ‚îÄ requests.py
‚îú‚îÄ‚îÄ responses.py
‚îú‚îÄ‚îÄ tasks.py
‚îú‚îÄ‚îÄ celery_app.py
‚îú‚îÄ‚îÄ models.py
‚îú‚îÄ‚îÄ database.py
‚îú‚îÄ‚îÄ status_enum.py      # üÜï enum –≤—ã–Ω–µ—Å–µ–Ω –æ—Ç–¥–µ–ª—å–Ω–æ
‚îî‚îÄ‚îÄ repository.py       # üÜï –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ë–î
```

api\_service/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ routes.py
‚îú‚îÄ‚îÄ requests.py
‚îú‚îÄ‚îÄ responses.py
‚îú‚îÄ‚îÄ tasks.py
‚îú‚îÄ‚îÄ celery\_app.py
‚îú‚îÄ‚îÄ models.py
‚îî‚îÄ‚îÄ database.py

````

---

## üîß Dockerfile
```dockerfile
FROM python:3.12-slim AS runtime

RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential libpq-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /usr/src/app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

ENV PYTHONUNBUFFERED=1 \
    DATABASE_URL=postgresql+asyncpg://user:pass@db:5432/app_db \
    REDIS_URL=redis://redis:6379/0 \
    TASK_QUEUE=parser:tasks \
    RESULT_PREFIX=parser:results:

# üìù –ù–µ –∑–∞–¥–∞—ë–º CMD –∑–¥–µ—Å—å. –ö–∞–∂–¥–æ–º—É —Å–µ—Ä–≤–∏—Å—É –≤ docker-compose
# –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–∞ —Å–≤–æ—è –∫–æ–º–∞–Ω–¥–∞: Uvicorn –¥–ª—è "api" –∏ Celery –¥–ª—è "api_worker".
````

---

## üì¶ requirements.txt

```text
fastapi==0.110.0
uvicorn[standard]==0.29.0
httpx[http2]==0.27.0
redis==5.0.5                    # client –¥–ª—è –æ—á–µ—Ä–µ–¥–∏
celery[redis]==5.4.0
sqlalchemy[asyncio]==2.0.30
asyncpg==0.29.0
alembic==1.13.1
pydantic==2.7.1
python-dotenv==1.0.1
```

---

### üêç **celery\_app.py** ‚Äì –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Celery

```python
from __future__ import annotations

import os
from celery import Celery

REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379/0")

celery_app = Celery(
    "api_service",
    broker=REDIS_URL,
    backend=REDIS_URL,
    include=["tasks"],
)

celery_app.conf.task_default_queue = "api"
celery_app.conf.timezone = "UTC"
```

---

### üêç **status\_enum.py** ‚Äì –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤

```python
from enum import StrEnum


class StatusEnum(StrEnum):
    pending = "pending"
    processing = "processing"
    success = "success"
    failure = "failure"
```

---

### üêç **models.py** ‚Äì SQLAlchemy ORM (–¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å)

```python
from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlalchemy import Enum, func
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column

from status_enum import StatusEnum


class Base(DeclarativeBase):
    pass


class ParseRequest(Base):
    """–¢–∞–±–ª–∏—Ü–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥."""

    __tablename__ = "parse_requests"

    id: Mapped[int] = mapped_column(primary_key=True)
    url: Mapped[str]
    status: Mapped[StatusEnum] = mapped_column(Enum(StatusEnum), default=StatusEnum.pending)
    title: Mapped[Optional[str]]
    html_content: Mapped[Optional[str]]

    created_at: Mapped[datetime] = mapped_column(default=datetime.utcnow, server_default=func.now())
    updated_at: Mapped[datetime] = mapped_column(
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
        server_default=func.now(),
    )
```

---

### üêç **database.py** ‚Äì async engine + helpers

```python
from __future__ import annotations

import os
from contextlib import asynccontextmanager

from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+asyncpg://user:pass@db:5432/app_db")

engine = create_async_engine(DATABASE_URL, echo=False)
AsyncSessionLocal = sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)


@asynccontextmanager
async def get_session():  # Dependency –¥–ª—è FastAPI
    async with AsyncSessionLocal() as session:
        yield session
```

---

### üêç **requests.py** ‚Äì –≤—Ö–æ–¥–Ω—ã–µ —Å—Ö–µ–º—ã

```python
from __future__ import annotations

from pydantic import BaseModel, HttpUrl, Field


class ParseAsyncCreate(BaseModel):
    url: HttpUrl = Field(..., example="https://example.com")


class ParseSyncQuery(BaseModel):
    url: HttpUrl = Field(..., example="https://example.com")
```

---

### üêç **responses.py** ‚Äì –≤—ã—Ö–æ–¥–Ω—ã–µ —Å—Ö–µ–º—ã

```python
from __future__ import annotations

from typing import Optional

from pydantic import BaseModel, HttpUrl

from status_enum import StatusEnum


class ParseAsyncResponse(BaseModel):
    request_id: int
    status: StatusEnum


class StatusResponse(BaseModel):
    request_id: int
    status: StatusEnum


class ResultResponse(BaseModel):
    request_id: int
    status: StatusEnum
    title: Optional[str] = None
    html: Optional[str] = None


class SyncResult(BaseModel):
    title: str
    html: str
    url: HttpUrl
```

---

### üêç **tasks.py** ‚Äì Celery‚Äë–∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞

```python
from __future__ import annotations

import asyncio
import json
import os
from time import time

import redis
from celery import shared_task
from sqlalchemy import select, update

from celery_app import celery_app
from database import AsyncSessionLocal, engine
from models import ParseRequest, StatusEnum

REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379/0")
TASK_QUEUE = os.getenv("TASK_QUEUE", "parser:tasks")
RESULT_PREFIX = os.getenv("RESULT_PREFIX", "parser:results:")


@shared_task(name="api.parse_url", queue="api")
def parse_url_task(request_id: int, url: str) -> None:
    """–ö–ª–∞–¥—ë—Ç –∑–∞–¥–∞–Ω–∏–µ –≤ Redis, –∂–¥—ë—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∑–∞—Ç–µ–º –ø–∏—à–µ—Ç –µ–≥–æ –≤ –ë–î."""
    r = redis.Redis.from_url(REDIS_URL, decode_responses=True)

    # 1) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –ø–∞—Ä—Å–µ—Ä—É
    payload = json.dumps({"id": request_id, "url": url})
    r.lpush(TASK_QUEUE, payload)

    # 2) –ë–ª–æ–∫–∏—Ä—É—é—â–µ –∂–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–º–∞–∫—Å 30 c)
    res_key = f"{RESULT_PREFIX}{request_id}"
    deadline = time() + 30
    result_data: dict[str, str] | None = None
    while time() < deadline:
        data = r.get(res_key)
        if data:
            result_data = json.loads(data)
            r.delete(res_key)
            break
        r.sleep(1)  # Redis >= 5 client helper

    async def _write(status: StatusEnum, title: str | None = None, html: str | None = None):
        async with AsyncSessionLocal() as session:
            stmt = (
                update(ParseRequest)
                .where(ParseRequest.id == request_id)
                .values(status=status, title=title, html_content=html)
            )
            await session.execute(stmt)
            await session.commit()

    if not result_data:
        asyncio.run(_write(StatusEnum.failure, title=None, html="Timeout waiting result"))
        return

    if result_data.get("status") == "success":
        asyncio.run(_write(StatusEnum.success, result_data.get("title"), result_data.get("html")))
    else:
        asyncio.run(_write(StatusEnum.failure, html=result_data.get("error")))
```

---

### üêç **repository.py** ‚Äì CRUD‚Äë–æ–ø–µ—Ä–∞—Ü–∏–∏

```python
from __future__ import annotations

from sqlalchemy import select, update
from sqlalchemy.ext.asyncio import AsyncSession

from models import ParseRequest
from status_enum import StatusEnum


class ParseRepository:
    """–ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ parse_requests."""

    @staticmethod
    async def create(session: AsyncSession, url: str) -> ParseRequest:
        req = ParseRequest(url=url, status=StatusEnum.pending)
        session.add(req)
        await session.commit()
        await session.refresh(req)
        return req

    @staticmethod
    async def by_id(session: AsyncSession, request_id: int) -> ParseRequest | None:
        res = await session.execute(select(ParseRequest).where(ParseRequest.id == request_id))
        return res.scalar_one_or_none()

    @staticmethod
    async def update_status(
        session: AsyncSession,
        request_id: int,
        status: StatusEnum,
        *,
        title: str | None = None,
        html: str | None = None,
    ) -> None:
        stmt = (
            update(ParseRequest)
            .where(ParseRequest.id == request_id)
            .values(status=status, title=title, html_content=html)
        )
        await session.execute(stmt)
        await session.commit()
```

---

### üêç **routes.py** ‚Äì HTTP‚Äë—ç–Ω–¥–ø–æ–π–Ω—Ç—ã (–±–µ–∑ –ø—Ä—è–º–æ–≥–æ SQLAlchemy)

```python
from __future__ import annotations

import httpx
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from database import get_session
from repository import ParseRepository as Repo
from requests import ParseAsyncCreate, ParseSyncQuery
from responses import (
    ParseAsyncResponse,
    StatusResponse,
    ResultResponse,
    SyncResult,
)
from status_enum import StatusEnum
from tasks import parse_url_task

PARSER_HTTP = "http://parser:8001/fetch"

router = APIRouter()


@router.post("/parse_async", response_model=ParseAsyncResponse, status_code=status.HTTP_202_ACCEPTED)
async def parse_async(payload: ParseAsyncCreate, session: AsyncSession = Depends(get_session)):
    req = await Repo.create(session, str(payload.url))
    parse_url_task.delay(req.id, str(payload.url))
    return ParseAsyncResponse(request_id=req.id, status=req.status)


@router.get("/status/{request_id}", response_model=StatusResponse)
async def status(request_id: int, session: AsyncSession = Depends(get_session)):
    obj = await Repo.by_id(session, request_id)
    if not obj:
        raise HTTPException(status_code=404, detail="Not found")
    return StatusResponse(request_id=obj.id, status=obj.status)


@router.get("/result/{request_id}", response_model=ResultResponse)
async def result(request_id: int, session: AsyncSession = Depends(get_session)):
    obj = await Repo.by_id(session, request_id)
    if not obj:
        raise HTTPException(status_code=404, detail="Not found")
    return ResultResponse(
        request_id=obj.id,
        status=obj.status,
        title=obj.title,
        html=obj.html_content,
    )


@router.get("/parse_sync", response_model=SyncResult)
async def parse_sync(query: ParseSyncQuery):
    async with httpx.AsyncClient(timeout=10, follow_redirects=True) as client:
        try:
            resp = await client.get(PARSER_HTTP, params={"url": query.url})
            resp.raise_for_status()
        except httpx.HTTPError as exc:
            raise HTTPException(status_code=502, detail=str(exc)) from exc
    data = resp.json()
    return SyncResult(url=query.url, title=data["title"], html=data["html"])
```

---

### üêç **main.py** ‚Äì FastAPI + lifespan

```python
from __future__ import annotations

from contextlib import asynccontextmanager

from fastapi import FastAPI

from routes import router


@asynccontextmanager
async def lifespan(app: FastAPI):  # noqa: D401
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ / –ª–æ–≥–∏, –Ω–æ –ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ yield
    yield


app = FastAPI(title="API Service", version="1.0.0", lifespan=lifespan)
app.include_router(router)
```

---

## üîÑ Alembic (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ)

* `alembic init alembic`, –≤ `env.py`: `target_metadata = models.Base.metadata`
* `alembic revision --autogenerate -m "create parse_requests"`

---

## üê≥ docker-compose ‚Äî –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª

```yaml
version: "3.9"

services:
  # --- DB & Redis -------------------------------------------------
  db:
    image: postgres:15-alpine
    container_name: db
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: app_db
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "user"]
      interval: 5s
      retries: 5
    volumes:
      - dbdata:/var/lib/postgresql/data
    networks: [backend]

  redis:
    image: redis:7-alpine
    container_name: redis
    healthcheck:
      test: ["CMD", "redis-cli", "PING"]
      interval: 5s
      retries: 5
    networks: [backend]

  # --- Parser microservice ---------------------------------------
  parser:
    build:
      context: ./parser_service
    container_name: parser_service
    environment:
      REDIS_URL: redis://redis:6379/0
      TASK_QUEUE: parser:tasks
      RESULT_PREFIX: parser:results:
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health" ]  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –¥–æ–±–∞–≤–∏—à—å —ç–Ω–¥–ø–æ–π–Ω—Ç
      interval: 10s
      retries: 3
    networks: [backend]

  # --- API (HTTP) -------------------------------------------------
  api:
    build:
      context: ./api_service
    container_name: api_service
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    environment:
      DATABASE_URL: postgresql+asyncpg://user:pass@db:5432/app_db
      REDIS_URL: redis://redis:6379/0
      TASK_QUEUE: parser:tasks
      RESULT_PREFIX: parser:results:
    depends_on:
      db:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      parser:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/docs" ]
      interval: 10s
      retries: 3
    networks: [backend]

  # --- Celery worker ---------------------------------------------
  api_worker:
    build:
      context: ./api_service
    container_name: api_worker
    command: celery -A celery_app worker --loglevel=info --concurrency=4 -Q api
    environment:
      DATABASE_URL: postgresql+asyncpg://user:pass@db:5432/app_db
      REDIS_URL: redis://redis:6379/0
      TASK_QUEUE: parser:tasks
      RESULT_PREFIX: parser:results:
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      parser:
        condition: service_healthy
    networks: [backend]

  # --- Alembic migrations (one‚Äëshot) ------------------------------
  migrate:
    build:
      context: ./api_service
    container_name: migrate
    command: alembic upgrade head
    environment:
      DATABASE_URL: postgresql+asyncpg://user:pass@db:5432/app_db
    depends_on:
      db:
        condition: service_healthy
    restart: "no"
    networks: [backend]

# ---------------------------------------------------------------
volumes:
  dbdata:

networks:
  backend:
    driver: bridge
```
